# AUTOGENERATED! DO NOT EDIT! File to edit: ../src/library/05_Sequencing.ipynb.

# %% auto 0
__all__ = ['Sequencer', 'PipelineSequencer', 'BaselineSequencer', 'BaselinePlusContextSequencer',
           'BaselinePlusFragmentsSequencer', 'BaselinePlusContextPlusFragmentsSequencer']

# %% ../src/library/05_Sequencing.ipynb 2
#| code-summary: specify the abstract class for implementing target item sequencing strategies
from abc import ABC, abstractmethod
from typing import List, Dict, Optional


class Sequencer(ABC):

    """
    Abstract base class for implementing target item sequencing strategies. To create a custom sequencer, inherit from this class and override the sequence method.
    """

    @abstractmethod
    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = '') -> Dict[str, object]:
        """
        Identifies the sequence of target items in the input text using the
        provided Segmenter and Matcher instances.

        Parameters:
            text (str): The input text to be segmented.

        Returns:
            Dict[str, List[str]]: Dictionary containing:
                - 'target_context': The string containing the context of the target items. (if applicable)
                - 'target_items': The list of target items
                - 'response_transcript': The input text
                - 'response_units': The list of response units, a dictionary of the form {'text': str, 'span' [(start, end)]}
                - 'matches': a 2-D boolean numpy array of shape (len(target_items), len(response_units)) containing True if the target item matches the response unit at the corresponding index.
        """
        pass


# %% ../src/library/05_Sequencing.ipynb 4
#| code-summary: implement a pipeline sequencer that composes a segmenter and matcher to identify the sequence of target items generated in a response text
from .segmenting import Segmenter
from .matching import Matcher
import numpy as np

class PipelineSequencer(Sequencer):
    """
    Concrete implementation of Sequencer that composes Segmenter and Matcher
    classes to identify the sequence of target items generated in a response text.
    """

    def __init__(self, segmenter: Segmenter, matcher: Matcher):
        """
        Initializes the PipelineSequencer with a given Segmenter and Matcher.

        Parameters:
            segmenter (Segmenter): An instance of a concrete Segmenter implementation.
        matcher (Matcher): An instance of a concrete Matcher implementation.
        """
        self.segmenter = segmenter
        self.matcher = matcher

    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = '') -> Dict[str, object]:
        """
        Identifies the sequence of target items in the input text using the
        provided Segmenter and Matcher instances.

        Parameters:
            text (str): The input text to be segmented.

        Returns:
            Dict[str, List[str]]: Dictionary containing:
                - 'target_context': The string containing the context of the target items. (if applicable)
                - 'target_items': The list of target items
                - 'response_transcript': The input text
                - 'response_units': The list of response units, a dictionary of the form {'text': str, 'span' [(start, end)]}
                - 'matches': list of lists representing a 2-D boolean numpy array of shape (len(target_items), len(response_units)) containing True if the target item matches the response unit at the corresponding index.
        """

        response_units = self.segmenter(response_transcript)
        matching = self.matcher(
            response_units, target_items, response_transcript, target_context)

        return {
            'target_context': target_context,
            'target_items': target_items,
            'response_transcript': response_transcript,
            'response_units': response_units,
            'matches': matching
        }

# %% ../src/library/05_Sequencing.ipynb 8
#| code-summary: implement a range of reference sequencers used for comparison against a baseline sequencer
from .segmenting import MultiSentenceFragmentsSegmenter, SentenceSegmenter
from .scoring import ContextualizedEmbeddingScorer, SentenceTransformerScorer
from .matching import MaximumScoreMatcher

class BaselineSequencer(Sequencer):
    
    def __init__(self):
        model_name = 'all-mpnet-base-v2'
        segmenter = SentenceSegmenter()
        scorer = SentenceTransformerScorer(
            model_name='all-mpnet-base-v2')
        matcher = MaximumScoreMatcher(scorer)
        self.sequencer = PipelineSequencer(segmenter, matcher)

    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = ''
        ) -> Dict[str, object]:

            return self.sequencer(response_transcript, target_items, target_context)

class BaselinePlusContextSequencer(Sequencer):
    def __init__(self):
        layer_depth = 1
        model_name = 'sentence-transformers/all-mpnet-base-v2'
        segmenter = SentenceSegmenter()
        scorer = ContextualizedEmbeddingScorer(
            model_name='sentence-transformers/all-mpnet-base-v2',
            layer_depth=layer_depth)
        matcher = MaximumScoreMatcher(scorer)
        self.sequencer = PipelineSequencer(segmenter, matcher)

    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = ''
        ) -> Dict[str, object]:

            return self.sequencer(response_transcript, target_items, target_context)

class BaselinePlusFragmentsSequencer(Sequencer):

    def __init__(self):
        min_tokens = 2
        max_sentences = 2
        model_name = 'all-mpnet-base-v2'
        segmenter = MultiSentenceFragmentsSegmenter(
            max_sentences=max_sentences, min_tokens=min_tokens)
        scorer = SentenceTransformerScorer(
            model_name='all-mpnet-base-v2')
        matcher = MaximumScoreMatcher(scorer)
        self.sequencer = PipelineSequencer(segmenter, matcher)

    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = ''
        ) -> Dict[str, object]:

            return self.sequencer(response_transcript, target_items, target_context)

class BaselinePlusContextPlusFragmentsSequencer(Sequencer):

    def __init__(self):
        layer_depth = 1
        min_tokens = 2
        max_sentences = 2
        model_name = 'sentence-transformers/all-mpnet-base-v2'
        segmenter = MultiSentenceFragmentsSegmenter(
            max_sentences=max_sentences, min_tokens=min_tokens)
        scorer = ContextualizedEmbeddingScorer(
            model_name='sentence-transformers/all-mpnet-base-v2', 
            layer_depth=layer_depth)
        matcher = MaximumScoreMatcher(scorer)
        self.sequencer = PipelineSequencer(segmenter, matcher)

    def __call__(
        self, response_transcript: str, target_items: List[str], target_context: str = ''
        ) -> Dict[str, object]:

            return self.sequencer(response_transcript, target_items, target_context)
