{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBS Narrative Recall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class SBS_NarrativeDataset(Dataset):\n",
    "    def __init__(self, data_directory):\n",
    "        \n",
    "        # each response file represents a sample; these are named based on '{story_name}_{subject_id}_{iteration}'\n",
    "        self.data_directory = data_directory\n",
    "        self.text_directory = os.path.join(data_directory, 'texts')\n",
    "        self.sequence_directory = os.path.join(data_directory, 'sequences', 'human')\n",
    "        self.response_files = []\n",
    "        self.stories = {}\n",
    "        for path, subdirs, files in os.walk(self.text_directory):\n",
    "            for name in files:\n",
    "                if name.count('_') == 2:\n",
    "                    self.response_files.append(name)\n",
    "                else:\n",
    "                    with open(os.path.join(path, name), 'r', encoding='utf-8') as f:\n",
    "                        self.stories[name[:-4]] = f.read()\n",
    "\n",
    "        self.trial_indices = np.arange(len(self.response_files))\n",
    "\n",
    "    def _retrieve_story_text(self, response_file_name):\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        return self.stories[story_name]\n",
    "\n",
    "    def _retrieve_response_text(self, response_file_name):\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        with open(os.path.join(self.text_directory, story_name, response_file_name), 'r') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    def _retrieve_response_sequence(self, response_file_name):\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        with open(os.path.join(self.sequence_directory, story_name, response_file_name[:-3]+'json'), 'r') as f:\n",
    "            return json.load(f)\n",
    "        \n",
    "    def _prepare_match_matrix(self, response_sequence):\n",
    "        matchings = response_sequence['correspondences']\n",
    "        match_matrix = np.zeros(\n",
    "            (len(response_sequence['source_units']), len(response_sequence['response_units'])), dtype=bool)\n",
    "\n",
    "        for response_index, matched_target in enumerate(matchings):\n",
    "            if matched_target > -1:\n",
    "                match_matrix[matched_target, response_index] = True\n",
    "        return match_matrix\n",
    "    \n",
    "    def _prepare_target_items(self, story_text, response_sequence):\n",
    "        updated_unit_start = [story_text.find(unit) for unit in response_sequence['source_units']]\n",
    "        \n",
    "        for index, unit in enumerate(response_sequence['source_units']):\n",
    "            assert(updated_unit_start[index] > -1)\n",
    "\n",
    "        return [{'text': unit, 'spans':[(start, start+len(unit))]} for unit, start in zip(\n",
    "            response_sequence['source_units'], updated_unit_start)]\n",
    "    \n",
    "    def _prepare_response_units(self, response_text, response_sequence):\n",
    "        updated_text = [\n",
    "            response_text[span[0]:span[1]].strip() for span in response_sequence['response_spans']]\n",
    "\n",
    "        return [{'text': unit, 'spans':[(span[0], span[0]+len(unit))]} for unit, span in zip(\n",
    "            updated_text, response_sequence['response_spans'])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.response_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        trials = []\n",
    "        for trial_idx in np.atleast_1d(self.trial_indices[idx]):\n",
    "\n",
    "            response_file_name = self.response_files[trial_idx]\n",
    "            story_text = self._retrieve_story_text(response_file_name)\n",
    "            response_text = self._retrieve_response_text(response_file_name)\n",
    "            response_sequence = self._retrieve_response_sequence(response_file_name)\n",
    "\n",
    "            trials.append({\n",
    "                'target_context': story_text, \n",
    "                'target_items': self._prepare_target_items(story_text, response_sequence), \n",
    "                'response_transcript': response_text, \n",
    "                'response_units': self._prepare_response_units(response_text, response_sequence), \n",
    "                'matches': self._prepare_match_matrix(response_sequence)})\n",
    "            \n",
    "        return trials[0] if len(trials) == 1 else trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_context': 'It was a hot, sunny day and Kaylie and Rachel decided to take advantage of their off day and take a trip to the beach. The sun was an optimistic yellow pellet, blistering in the sky as they were on their way to Old Orchard Beach in Maine. Once arriving and walking from the parking lot, they spotted the crystal clear water that faded into a deep blue on the horizon. The beach was swarming with people. Some on yellow, orange, white, and pink towels, while others were seen stretched out on lounge chairs with broad-brimmed hats shading their eyes from the rays of the sun. Children were decorating sandcastles with smooth, round seashells, and Kaylie decided to stretch out on her towel in the sand for a quick nap while Rachel went to cool off in the ocean. \\nThe sun shined on the water, causing it to look like a million little crystals. Just before making it to the surf, Rachel saw a little girl with freckles in a light purple bathing suit and little yellow floaties on her arms. The girl darted in front of Rachel, closely followed by a boy in green swimming shorts. Rachel smiled as she reminisced on memories of beach days with her brothers. After spending some time in the water, she looked up and saw four teenagers flying colorful paragliders. She thought to herself that the day was truly perfect, and all anxieties from her daily life were absent for a while. She closed her eyes for a few seconds to savor the moment before going to lie down next to Kaylie in the warm sand.\\n',\n",
       " 'target_items': [{'text': 'It was a hot, sunny day ', 'spans': [(0, 24)]},\n",
       "  {'text': 'and Kaylie and Rachel ', 'spans': [(24, 46)]},\n",
       "  {'text': 'decided to take advantage of their off day ', 'spans': [(46, 89)]},\n",
       "  {'text': 'and take a trip to the beach. ', 'spans': [(89, 119)]},\n",
       "  {'text': 'The sun was an optimistic yellow pellet, ', 'spans': [(119, 160)]},\n",
       "  {'text': 'blistering in the sky as they were on their way ',\n",
       "   'spans': [(160, 208)]},\n",
       "  {'text': 'to Old Orchard Beach ', 'spans': [(208, 229)]},\n",
       "  {'text': 'in Maine. ', 'spans': [(229, 239)]},\n",
       "  {'text': 'Once arriving and walking from the parking lot, ',\n",
       "   'spans': [(239, 287)]},\n",
       "  {'text': 'they spotted the crystal clear water ', 'spans': [(287, 324)]},\n",
       "  {'text': 'that faded into a deep blue on the horizon.',\n",
       "   'spans': [(324, 367)]},\n",
       "  {'text': 'The beach was swarming with people. ', 'spans': [(368, 404)]},\n",
       "  {'text': 'Some on yellow, orange, white, and pink towels, ',\n",
       "   'spans': [(404, 452)]},\n",
       "  {'text': 'while others were seen stretched out on lounge chairs ',\n",
       "   'spans': [(452, 506)]},\n",
       "  {'text': 'with broad-brimmed hats ', 'spans': [(506, 530)]},\n",
       "  {'text': 'shading their eyes from the rays of the sun. ',\n",
       "   'spans': [(530, 575)]},\n",
       "  {'text': 'Children were decorating sandcastles with smooth, round seashells, ',\n",
       "   'spans': [(575, 642)]},\n",
       "  {'text': 'and Kaylie decided to stretch out on her towel ',\n",
       "   'spans': [(642, 689)]},\n",
       "  {'text': 'in the sand for a quick nap ', 'spans': [(689, 717)]},\n",
       "  {'text': 'while Rachel went to cool off in the ocean. ',\n",
       "   'spans': [(717, 761)]},\n",
       "  {'text': 'The sun shined on the water, ', 'spans': [(762, 791)]},\n",
       "  {'text': 'causing it to look like a million little crystals. ',\n",
       "   'spans': [(791, 842)]},\n",
       "  {'text': 'Just before making it to the surf, ', 'spans': [(842, 877)]},\n",
       "  {'text': 'Rachel saw a little girl with freckles ', 'spans': [(877, 916)]},\n",
       "  {'text': 'in a light purple bathing suit ', 'spans': [(916, 947)]},\n",
       "  {'text': 'and little yellow floaties on her arms. ', 'spans': [(947, 987)]},\n",
       "  {'text': 'The girl darted in front of Rachel, ', 'spans': [(987, 1023)]},\n",
       "  {'text': 'closely followed by a boy ', 'spans': [(1023, 1049)]},\n",
       "  {'text': 'in green swimming shorts. ', 'spans': [(1049, 1075)]},\n",
       "  {'text': 'Rachel smiled as she reminisced on memories of beach days ',\n",
       "   'spans': [(1075, 1133)]},\n",
       "  {'text': 'with her brothers. ', 'spans': [(1133, 1152)]},\n",
       "  {'text': 'After spending some time in the water, ', 'spans': [(1152, 1191)]},\n",
       "  {'text': 'she looked up and', 'spans': [(1191, 1208)]},\n",
       "  {'text': 'saw four teenagers ', 'spans': [(1209, 1228)]},\n",
       "  {'text': 'flying colorful paragliders. ', 'spans': [(1228, 1257)]},\n",
       "  {'text': 'She thought to herself that the day was truly perfect, ',\n",
       "   'spans': [(1257, 1312)]},\n",
       "  {'text': 'and all anxieties from her daily life were absent for a while. ',\n",
       "   'spans': [(1312, 1375)]},\n",
       "  {'text': 'She closed her eyes for a few seconds to savor the moment ',\n",
       "   'spans': [(1375, 1433)]},\n",
       "  {'text': 'before going to lie down next to Kaylie ',\n",
       "   'spans': [(1433, 1473)]},\n",
       "  {'text': 'in the warm sand.', 'spans': [(1473, 1490)]}],\n",
       " 'response_transcript': 'It was a hot, sunny day and Rachel and her friend Kaylie decided it would be a good day to go to the beach.  They headed out to Old Orchard beach in Maine.  The sun looked like a hot, yellow pellet in the sky.   There were people laying under beach umbrellas wearing wide brimmed hats. Rachael decided that she would like to lay down in the sun before going swimming.  Kaylie dedcided to go for a swim.  A little girl in a light purple bathing suit with two floaties darted out in front of her followed closely by a boy in green shorts.  Kaylie smiled to herself remembering long past beach days with her brothers.  She saw 4 teenagers flying paragliders.  She thought about this as she walked over to lay down next to Rachel, thinking about what a perfect day this was turning out to be.',\n",
       " 'response_units': [{'text': 'It was a hot, sunny day', 'spans': [(0, 23)]},\n",
       "  {'text': 'and Rachel and her friend Kaylie', 'spans': [(24, 56)]},\n",
       "  {'text': 'decided it would be a good day to go to the beach.',\n",
       "   'spans': [(57, 107)]},\n",
       "  {'text': 'They headed out to Old Orchard beach', 'spans': [(109, 145)]},\n",
       "  {'text': 'in Maine.', 'spans': [(146, 155)]},\n",
       "  {'text': 'The sun looked like a hot, yellow pellet in the sky',\n",
       "   'spans': [(157, 208)]},\n",
       "  {'text': 'There were people laying under beach umbrellas wearing wide brimmed hats.',\n",
       "   'spans': [(212, 285)]},\n",
       "  {'text': 'Rachael decided that she would like to lay down in the sun before going swimming.',\n",
       "   'spans': [(286, 367)]},\n",
       "  {'text': 'Kaylie dedcided to go for a swim.', 'spans': [(369, 402)]},\n",
       "  {'text': 'A little girl', 'spans': [(404, 417)]},\n",
       "  {'text': 'in a light purple bathing suit', 'spans': [(418, 448)]},\n",
       "  {'text': 'with two floaties', 'spans': [(449, 466)]},\n",
       "  {'text': 'darted out in front of her', 'spans': [(467, 493)]},\n",
       "  {'text': 'followed closely by a boy', 'spans': [(494, 519)]},\n",
       "  {'text': 'in green shorts', 'spans': [(520, 535)]},\n",
       "  {'text': '.  Kaylie smiled to herself remembering long past beach days',\n",
       "   'spans': [(535, 595)]},\n",
       "  {'text': 'with her brothers', 'spans': [(596, 613)]},\n",
       "  {'text': '.  She saw 4 teenagers', 'spans': [(613, 635)]},\n",
       "  {'text': 'flying paragliders', 'spans': [(636, 654)]},\n",
       "  {'text': '.  She thought about this as she walked over to lay down next to Rachel,',\n",
       "   'spans': [(654, 726)]},\n",
       "  {'text': 'thinking about what a perfect day this was turning out to be',\n",
       "   'spans': [(727, 787)]}],\n",
       " 'matches': array([[ True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False,  True, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = 'C:/Users/gunnj/compmempy/data/narrative'\n",
    "dataset = SBS_NarrativeDataset(data_directory)\n",
    "\n",
    "example_entry = dataset[0]\n",
    "example_entry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import chardet\n",
    "import hdf5storage\n",
    "\n",
    "class SensesDataset(Dataset):\n",
    "    def __init__(self, hdf5_file_path, sense_pool_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            hdf5_file_path (str): Path to the HDF5 file.\n",
    "            sense_pool_path (str): Path to the sense pool file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Load the data from the specified HDF5 file\n",
    "        # You can customize this part to load your data\n",
    "        self.data = hdf5storage.read(path='/data', filename=hdf5_file_path)\n",
    "\n",
    "        self.trial_count = len(self.data[\"subject\"])\n",
    "        self.trial_indices = np.arange(self.trial_count)\n",
    "        with open(sense_pool_path, mode='rb') as f:\n",
    "            raw_data = f.read()\n",
    "            detected_encoding = chardet.detect(raw_data)['encoding']\n",
    "            self.sense_pool = raw_data.decode(detected_encoding).split('\\n')\n",
    "        \n",
    "        # Set the transform if provided\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of trials in the dataset.\n",
    "        \"\"\"\n",
    "        return self.trial_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a trial from the dataset at the specified index.\n",
    "\n",
    "        Args:\n",
    "            trial_idx (int): Index of the trial to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            sample: The retrieved sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # pres_itemids selects the indices from sense_pool of the target items\n",
    "        trials = []\n",
    "        for trial_idx in np.atleast_1d(self.trial_indices[idx]):\n",
    "            senses = self.data['pres_itemids'][trial_idx]\n",
    "            target_items = [self.sense_pool[each-1].strip() for each in senses if each != 0]\n",
    "            \n",
    "            # response units are the segments of the transcript selected by raters and their spans in the transcript\n",
    "            response_transcript = str(self.data['recall_transcript'][trial_idx][0])\n",
    "            response_units = [str(each) for each in self.data['response_units'][trial_idx] if str(each) != '']\n",
    "\n",
    "            # full response units include text *and* span representations contained in a dict\n",
    "            response_start_spans = [each-1 for each in self.data[\"response_unit_start\"][trial_idx] if each != 0]\n",
    "            response_end_spans = [each-1 for each in self.data[\"response_unit_end\"][trial_idx] if each != 0]\n",
    "            full_response_units = [{'text': unit, 'spans':[(start_span, end_span)]} for unit, start_span, end_span in zip(\n",
    "                response_units, response_start_spans, response_end_spans)]\n",
    "            \n",
    "            # matchings\n",
    "            match_matrix = np.zeros((len(target_items), len(response_units)), dtype=bool)\n",
    "            target_indices = np.array([each-1 for each in self.data['recalls'][trial_idx] if each != 0])\n",
    "\n",
    "            if len(target_indices) > 0:\n",
    "                match_matrix[target_indices, np.arange(len(response_units))] = True\n",
    "\n",
    "            trials.append({\n",
    "                'target_context': '', \n",
    "                'target_items': target_items, \n",
    "                'response_transcript': response_transcript, \n",
    "                'response_units': full_response_units, \n",
    "                'matches': match_matrix})\n",
    "            \n",
    "        return trials[0] if len(trials) == 1 else trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target_context': '',\n",
       "  'target_items': ['(n) ace (one of four playing cards in a deck having a single pip on its face)',\n",
       "   '(n) ace, adept, champion, sensation, maven, mavin, virtuoso, genius, hotshot, star, superstar, whiz, whizz, wizard, wiz (someone who is dazzlingly skilled in any field)',\n",
       "   '(n) ace (a serve that the receiver is unable to reach)',\n",
       "   '(v) breeze through, ace, pass with flying colors, sweep through, sail through, nail (succeed at easily) \"She sailed through her exams\"; \"You will pass with flying colors\"; \"She nailed her astrophysics course\"',\n",
       "   '(v) ace (serve an ace against (someone))',\n",
       "   '(n) one, 1, I, ace, single, unity (the smallest whole number or a numeral representing this number) \"he has the one but will need a two and three to go with it\"; \"they had lunch at one\"',\n",
       "   '(adj) ace, A-one, crack, first-rate, super, tiptop, topnotch, top-notch, tops (of the highest quality) \"an ace reporter\"; \"a crack shot\"; \"a first-rate golfer\"; \"a super party\"; \"played top-notch tennis\"; \"an athlete in tiptop condition\"; \"she is absolutely tops\"',\n",
       "   '(v) ace (play (a hole) in one stroke)',\n",
       "   '(n) 5: a combat pilot who has brought down at least five enemy airplanes'],\n",
       "  'response_transcript': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um, an ace can be someone that's really good at something.\",\n",
       "  'response_units': [{'text': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um,\",\n",
       "    'spans': [(0, 107)]},\n",
       "   {'text': \"in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um,\",\n",
       "    'spans': [(108, 241)]},\n",
       "   {'text': \"an ace can be someone that's really good at something\",\n",
       "    'spans': [(242, 295)]}],\n",
       "  'matches': array([[False,  True, False],\n",
       "         [False, False,  True],\n",
       "         [ True, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]])},\n",
       " {'target_context': '',\n",
       "  'target_items': ['(n) wake, backwash (the wave that spreads behind a boat as it moves forward) \"the motorboat\\'s wake capsized the canoe\"',\n",
       "   '(n) wake, viewing (a vigil held over a corpse the night before burial) \"there\\'s no weeping at an Irish wake\"',\n",
       "   '(v) wake up, awake, arouse, awaken, wake, come alive, waken (stop sleeping) \"She woke up to the sound of the alarm clock\"',\n",
       "   '(v) wake (be awake, be alert, be there)',\n",
       "   '(v) wake (make aware of) \"His words woke us to terrible facts of the situation\"',\n",
       "   '(v) awaken, wake, waken, rouse, wake up, arouse (cause to become awake or conscious) \"He was roused by the drunken men in the street\"; \"Please wake me at 6 AM.\"',\n",
       "   '(n) aftermath, wake, backwash (the consequences of an event (especially a catastrophic event)) \"the aftermath of war\"; \"in the wake of the accident no one knew how many had been injured\"',\n",
       "   '(v) inflame, stir up, wake, ignite, heat, fire up (arouse or excite feelings and passions) \"The ostentatious way of living of the rich ignites the hatred of the poor\"; \"The refugees\\' fate stirred up compassion around the world\"; \"Wake old feelings of hatred\"'],\n",
       "  'response_transcript': \"Um, wake can be, like, you, it's, it can be like a verb, like you are, um, waking up from sleep. Um, a wake can also be an, like, event, kind of like a funeral, or celebration of someone's life. Um, um, I feel like there's also a meaning of wake that has something to do with water, but I can't think of what it is, exactly. Like, waves, maybe, something to do with, like, the waves. Um I don't know. I don't know. I guess, like, um, a wake can also be, like, a mode on an alarm clock, 'cause like the sleep-wake, um. . . Yeah.\",\n",
       "  'response_units': [{'text': \"Um, wake can be, like, you, it's, it can be like a verb, like you are, um, waking up from sleep. Um\",\n",
       "    'spans': [(0, 99)]},\n",
       "   {'text': \"a wake can also be an, like, event, kind of like a funeral, or celebration of someone's life. Um, um\",\n",
       "    'spans': [(101, 201)]},\n",
       "   {'text': \"I feel like there's also a meaning of wake that has something to do with water, but I can't think of what it is, exactly. Like, waves, maybe, something to do with, like, the waves. Um I don't know. I don't know.\",\n",
       "    'spans': [(203, 414)]}],\n",
       "  'matches': array([[False, False,  True],\n",
       "         [False,  True, False],\n",
       "         [ True, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]])}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_tag = 'base' # unique identifier for this variation of notebook parameters\n",
    "output_dir = 'C:/Users/gunnj/workspace/response_sequencer/data/'\n",
    "\n",
    "dataset = SensesDataset(os.path.join(output_dir, f'{section_tag}_senses.h5'), os.path.join(output_dir, f'{section_tag}_sense_pool.txt'))\n",
    "\n",
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
