{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting data for use with a new library can be a time consuming process. \n",
    "If you're using multiple libraries with different data requirements, you may find yourself reformatting the same data multiple times, storing multiple copies of the same data in different formats, and struggling to synchronize changes between them.\n",
    "Rather than requiring users to reformat their data to fit the library, we we borrow an approach from [Pytorch](https://pytorch.org/).\n",
    "Instead of requiring data be specified in a specific way, Pytorch provides an abstract Dataset class that can be extended to provide a common interface for loading data from a variety of sources. \n",
    "Instead of generating the dataset in a new format, the job becomes to provide functions retrieve data samples from the original source and return them in the appropriate format.\n",
    "\n",
    "Here we outline this approach in more detail (often cribbing from the Pytorch documentation) and provide examples of how we have used it to load data in our own research.\n",
    "More specific instructions about what information a Dataset should return to work with applicable functions our library will be provided in their specific documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict\n",
    "\n",
    "class Dataset(ABC):\n",
    "    \"\"\"\n",
    "    `Dataset` is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
    "\n",
    "    - `__len__` so that len(dataset) returns the size of the dataset.\n",
    "    - `__getitem__` to support the indexing such that `dataset[i]` can be used to get ith sample\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __len__(self\n",
    "                )->int: # number of samples in the dataset\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __getitem__(self, idx: int) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Returns a sample from the dataset.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a toy example, the following class specifies the interface for a dataset that accesses a text file and treats each line as a separate sample to be represented as a Markdown object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path: str):\n",
    "        with open(dataset_path, 'r') as f:\n",
    "            self.data = f.read().split('\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.count('\\n')\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it to consider lines of this project's README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "This project explores the potential of automatic n\n"
     ]
    }
   ],
   "source": [
    "readme_dataset = TextDataset('../README.md')\n",
    "print(len(readme_dataset))\n",
    "print(readme_dataset[0][:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import chardet\n",
    "import hdf5storage\n",
    "\n",
    "class SensesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the Senses dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hdf5_file_path, sense_pool_path):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            hdf5_file_path (str): Path to the HDF5 file.\n",
    "            sense_pool_path (str): Path to the sense pool file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Load the data from the specified HDF5 file\n",
    "        # You can customize this part to load your data\n",
    "        self.data = hdf5storage.read(path='/data', filename=hdf5_file_path)\n",
    "\n",
    "        self.trial_count = len(self.data[\"subject\"])\n",
    "        self.trial_indices = np.arange(self.trial_count)\n",
    "        with open(sense_pool_path, mode='rb') as f:\n",
    "            raw_data = f.read()\n",
    "            detected_encoding = chardet.detect(raw_data)['encoding']\n",
    "            self.sense_pool = raw_data.decode(str(detected_encoding)).split('\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of trials in the dataset.\n",
    "        \"\"\"\n",
    "        return self.trial_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a trial from the dataset at the specified index.\n",
    "\n",
    "        Args:\n",
    "            trial_idx (int): Index of the trial to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            sample: The retrieved sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # pres_itemids selects the indices from sense_pool of the target items\n",
    "        trials = []\n",
    "        for trial_idx in np.atleast_1d(self.trial_indices[idx]):\n",
    "            senses = self.data['pres_itemids'][trial_idx]\n",
    "            target_items = [self.sense_pool[each-1].strip() for each in senses if each != 0]\n",
    "            \n",
    "            # response units are the segments of the transcript selected by raters and their spans in the transcript\n",
    "            response_transcript = str(self.data['recall_transcript'][trial_idx][0])\n",
    "            response_units = [str(each) for each in self.data['response_units'][trial_idx] if str(each) != '']\n",
    "\n",
    "            # full response units include text *and* span representations contained in a dict\n",
    "            response_start_spans = [each-1 for each in self.data[\"response_unit_start\"][trial_idx] if each != 0]\n",
    "            response_end_spans = [each-1 for each in self.data[\"response_unit_end\"][trial_idx] if each != 0]\n",
    "            full_response_units = [{'text': unit, 'spans':[(start_span, end_span)]} for unit, start_span, end_span in zip(\n",
    "                response_units, response_start_spans, response_end_spans)]\n",
    "            \n",
    "            # matchings\n",
    "            match_matrix = np.zeros((len(target_items), len(response_units)), dtype=bool)\n",
    "            target_indices = np.array([each-1 for each in self.data['recalls'][trial_idx] if each != 0])\n",
    "\n",
    "            if len(target_indices) > 0:\n",
    "                match_matrix[target_indices, np.arange(len(response_units))] = True\n",
    "\n",
    "            trials.append({\n",
    "                'target_context': '', \n",
    "                'target_items': target_items, \n",
    "                'response_transcript': response_transcript, \n",
    "                'response_units': full_response_units, \n",
    "                'matches': match_matrix})\n",
    "            \n",
    "        return trials[0] if len(trials) == 1 else trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For trials defining this dataset, participants were cued with a word and asked to generate all the senses of that word that they could think of.\n",
    "The dataset is organized as an HDF5 file paired with a text file containing the pool of senses that participants could generate.\n",
    "    \n",
    "Each item returned by this dataset is a dictionary with the following keys:\n",
    "\n",
    "- `target_context`: the story text \n",
    "- `target_items`: a list of dictionaries, each representing a target item in the story. \n",
    "- `response_transcript`: the response transcript  \n",
    "- `response_units`: a list of dictionaries, each representing a response unit in the response transcript.\n",
    "- `matches`: a boolean matrix indicating which response units match which target items\n",
    "\n",
    "Each dictionary specified by a target item or response unit has the following keys:  \n",
    "\n",
    "- `text`: the text of the target item  \n",
    "- `spans`: a list of tuples, each representing a span of the target item in the story text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_context': '',\n",
       " 'target_items': ['(n) ace (one of four playing cards in a deck having a single pip on its face)',\n",
       "  '(n) ace, adept, champion, sensation, maven, mavin, virtuoso, genius, hotshot, star, superstar, whiz, whizz, wizard, wiz (someone who is dazzlingly skilled in any field)',\n",
       "  '(n) ace (a serve that the receiver is unable to reach)',\n",
       "  '(v) breeze through, ace, pass with flying colors, sweep through, sail through, nail (succeed at easily) \"She sailed through her exams\"; \"You will pass with flying colors\"; \"She nailed her astrophysics course\"',\n",
       "  '(v) ace (serve an ace against (someone))',\n",
       "  '(n) one, 1, I, ace, single, unity (the smallest whole number or a numeral representing this number) \"he has the one but will need a two and three to go with it\"; \"they had lunch at one\"',\n",
       "  '(adj) ace, A-one, crack, first-rate, super, tiptop, topnotch, top-notch, tops (of the highest quality) \"an ace reporter\"; \"a crack shot\"; \"a first-rate golfer\"; \"a super party\"; \"played top-notch tennis\"; \"an athlete in tiptop condition\"; \"she is absolutely tops\"',\n",
       "  '(v) ace (play (a hole) in one stroke)',\n",
       "  '(n) 5: a combat pilot who has brought down at least five enemy airplanes'],\n",
       " 'response_transcript': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um, an ace can be someone that's really good at something.\",\n",
       " 'response_units': [{'text': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um,\",\n",
       "   'spans': [(0, 107)]},\n",
       "  {'text': \"in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um,\",\n",
       "   'spans': [(108, 241)]},\n",
       "  {'text': \"an ace can be someone that's really good at something\",\n",
       "   'spans': [(242, 295)]}],\n",
       " 'matches': array([[False,  True, False],\n",
       "        [False, False,  True],\n",
       "        [ True, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "section_tag = 'base' # unique identifier for this variation of notebook parameters\n",
    "output_dir = 'C:/Users/gunnj/workspace/response_sequencer/data/'\n",
    "\n",
    "dataset = SensesDataset(os.path.join(output_dir, f'{section_tag}_senses.h5'), os.path.join(output_dir, f'{section_tag}_sense_pool.txt'))\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBS Narrative Recall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "class SBS_NarrativeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the narrative free recall dataset provided by Sarah Brown-Schmidt's Conversation lab.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_directory):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Args:\n",
    "            data_directory (str): the directory containing the dataset files\n",
    "        \"\"\"\n",
    "\n",
    "        # each response file represents a sample; these are named based on '{story_name}_{subject_id}_{iteration}'\n",
    "        self.data_directory = data_directory\n",
    "        self.text_directory = os.path.join(data_directory, 'texts')\n",
    "        self.sequence_directory = os.path.join(data_directory, 'sequences', 'human')\n",
    "        self.response_files = []\n",
    "        self.stories = {}\n",
    "        for path, _, files in os.walk(self.text_directory):\n",
    "            for name in files:\n",
    "                if name.count('_') == 2:\n",
    "                    self.response_files.append(name)\n",
    "                else:\n",
    "                    with open(os.path.join(path, name), 'r', encoding='utf-8') as f:\n",
    "                        self.stories[name[:-4]] = f.read()\n",
    "\n",
    "        self.trial_indices = np.arange(len(self.response_files))\n",
    "\n",
    "    def _retrieve_story_text(self, response_file_name):\n",
    "        \"\"\"\n",
    "        Retrieves the story text for the specified response transcript.\n",
    "        \"\"\"\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        return self.stories[story_name]\n",
    "\n",
    "    def _retrieve_response_text(self, response_file_name):\n",
    "        \"\"\"\n",
    "        Retrieves the response text for the specified response transcript.\n",
    "        \"\"\"\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        with open(os.path.join(self.text_directory, story_name, response_file_name), 'r') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    def _retrieve_response_sequence(self, response_file_name):\n",
    "        \"\"\"\n",
    "        Retrieves the response sequence coded for the specified response transcript.\n",
    "        \"\"\"\n",
    "        story_name = response_file_name.split('_')[0]\n",
    "        with open(os.path.join(self.sequence_directory, story_name, response_file_name[:-3]+'json'), 'r') as f:\n",
    "            return json.load(f)\n",
    "        \n",
    "    def _prepare_match_matrix(self, response_sequence):\n",
    "        \"\"\"\n",
    "        Prepares a match matrix based on the specified response sequence.\n",
    "        \"\"\"\n",
    "        matchings = response_sequence['correspondences']\n",
    "        match_matrix = np.zeros(\n",
    "            (len(response_sequence['source_units']), len(response_sequence['response_units'])), dtype=bool)\n",
    "\n",
    "        for response_index, matched_target in enumerate(matchings):\n",
    "            if matched_target > -1:\n",
    "                match_matrix[matched_target, response_index] = True\n",
    "        return match_matrix\n",
    "    \n",
    "    def _prepare_target_items(self, story_text, response_sequence):\n",
    "        \"\"\"\n",
    "        Prepares a list of target items based on the specified response sequence and story text.\n",
    "        \"\"\"\n",
    "        updated_unit_start = [story_text.find(unit) for unit in response_sequence['source_units']]\n",
    "        \n",
    "        for index, unit in enumerate(response_sequence['source_units']):\n",
    "            assert(updated_unit_start[index] > -1)\n",
    "\n",
    "        return [{'text': unit, 'spans':[(start, start+len(unit))]} for unit, start in zip(\n",
    "            response_sequence['source_units'], updated_unit_start)]\n",
    "    \n",
    "    def _prepare_response_units(self, response_text, response_sequence):\n",
    "        \"\"\"\n",
    "        Prepares a list of response units based on the specified response sequence and response text.\n",
    "        \"\"\"\n",
    "        updated_text = [\n",
    "            response_text[span[0]:span[1]].strip() for span in response_sequence['response_spans']]\n",
    "\n",
    "        return [{'text': unit, 'spans':[(span[0], span[0]+len(unit))]} for unit, span in zip(\n",
    "            updated_text, response_sequence['response_spans'])]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.response_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a sample from the dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        trials = []\n",
    "        for trial_idx in np.atleast_1d(self.trial_indices[idx]):\n",
    "\n",
    "            response_file_name = self.response_files[trial_idx]\n",
    "            story_text = self._retrieve_story_text(response_file_name)\n",
    "            response_text = self._retrieve_response_text(response_file_name)\n",
    "            response_sequence = self._retrieve_response_sequence(response_file_name)\n",
    "\n",
    "            trials.append({\n",
    "                'target_context': story_text, \n",
    "                'target_items': self._prepare_target_items(story_text, response_sequence), \n",
    "                'response_transcript': response_text, \n",
    "                'response_units': self._prepare_response_units(response_text, response_sequence), \n",
    "                'matches': self._prepare_match_matrix(response_sequence)})\n",
    "            \n",
    "        return trials[0] if len(trials) == 1 else trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, participants perform free recall of a story they previously read.\n",
    "The dataset is organized into a directory of text files and spreadsheets that variously represent \n",
    "encoded stories, participant responses, and coding decisions made by the lab. \n",
    "\n",
    "Each item returned by this Dataset is structured similarly to those returned by the Senses Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_context': 'It was a hot, sunny day and Kaylie and Rachel decided to take advantage of their off day and take a trip to the beach. The sun was an optimistic yellow pellet, blistering in the sky as they were on their way to Old Orchard Beach in Maine. Once arriving and walking from the parking lot, they spotted the crystal clear water that faded into a deep blue on the horizon. The beach was swarming with people. Some on yellow, orange, white, and pink towels, while others were seen stretched out on lounge chairs with broad-brimmed hats shading their eyes from the rays of the sun. Children were decorating sandcastles with smooth, round seashells, and Kaylie decided to stretch out on her towel in the sand for a quick nap while Rachel went to cool off in the ocean. \\nThe sun shined on the water, causing it to look like a million little crystals. Just before making it to the surf, Rachel saw a little girl with freckles in a light purple bathing suit and little yellow floaties on her arms. The girl darted in front of Rachel, closely followed by a boy in green swimming shorts. Rachel smiled as she reminisced on memories of beach days with her brothers. After spending some time in the water, she looked up and saw four teenagers flying colorful paragliders. She thought to herself that the day was truly perfect, and all anxieties from her daily life were absent for a while. She closed her eyes for a few seconds to savor the moment before going to lie down next to Kaylie in the warm sand.\\n',\n",
       " 'target_items': [{'text': 'It was a hot, sunny day ', 'spans': [(0, 24)]},\n",
       "  {'text': 'and Kaylie and Rachel ', 'spans': [(24, 46)]},\n",
       "  {'text': 'decided to take advantage of their off day ', 'spans': [(46, 89)]},\n",
       "  {'text': 'and take a trip to the beach. ', 'spans': [(89, 119)]},\n",
       "  {'text': 'The sun was an optimistic yellow pellet, ', 'spans': [(119, 160)]},\n",
       "  {'text': 'blistering in the sky as they were on their way ',\n",
       "   'spans': [(160, 208)]},\n",
       "  {'text': 'to Old Orchard Beach ', 'spans': [(208, 229)]},\n",
       "  {'text': 'in Maine. ', 'spans': [(229, 239)]},\n",
       "  {'text': 'Once arriving and walking from the parking lot, ',\n",
       "   'spans': [(239, 287)]},\n",
       "  {'text': 'they spotted the crystal clear water ', 'spans': [(287, 324)]},\n",
       "  {'text': 'that faded into a deep blue on the horizon.',\n",
       "   'spans': [(324, 367)]},\n",
       "  {'text': 'The beach was swarming with people. ', 'spans': [(368, 404)]},\n",
       "  {'text': 'Some on yellow, orange, white, and pink towels, ',\n",
       "   'spans': [(404, 452)]},\n",
       "  {'text': 'while others were seen stretched out on lounge chairs ',\n",
       "   'spans': [(452, 506)]},\n",
       "  {'text': 'with broad-brimmed hats ', 'spans': [(506, 530)]},\n",
       "  {'text': 'shading their eyes from the rays of the sun. ',\n",
       "   'spans': [(530, 575)]},\n",
       "  {'text': 'Children were decorating sandcastles with smooth, round seashells, ',\n",
       "   'spans': [(575, 642)]},\n",
       "  {'text': 'and Kaylie decided to stretch out on her towel ',\n",
       "   'spans': [(642, 689)]},\n",
       "  {'text': 'in the sand for a quick nap ', 'spans': [(689, 717)]},\n",
       "  {'text': 'while Rachel went to cool off in the ocean. ',\n",
       "   'spans': [(717, 761)]},\n",
       "  {'text': 'The sun shined on the water, ', 'spans': [(762, 791)]},\n",
       "  {'text': 'causing it to look like a million little crystals. ',\n",
       "   'spans': [(791, 842)]},\n",
       "  {'text': 'Just before making it to the surf, ', 'spans': [(842, 877)]},\n",
       "  {'text': 'Rachel saw a little girl with freckles ', 'spans': [(877, 916)]},\n",
       "  {'text': 'in a light purple bathing suit ', 'spans': [(916, 947)]},\n",
       "  {'text': 'and little yellow floaties on her arms. ', 'spans': [(947, 987)]},\n",
       "  {'text': 'The girl darted in front of Rachel, ', 'spans': [(987, 1023)]},\n",
       "  {'text': 'closely followed by a boy ', 'spans': [(1023, 1049)]},\n",
       "  {'text': 'in green swimming shorts. ', 'spans': [(1049, 1075)]},\n",
       "  {'text': 'Rachel smiled as she reminisced on memories of beach days ',\n",
       "   'spans': [(1075, 1133)]},\n",
       "  {'text': 'with her brothers. ', 'spans': [(1133, 1152)]},\n",
       "  {'text': 'After spending some time in the water, ', 'spans': [(1152, 1191)]},\n",
       "  {'text': 'she looked up and', 'spans': [(1191, 1208)]},\n",
       "  {'text': 'saw four teenagers ', 'spans': [(1209, 1228)]},\n",
       "  {'text': 'flying colorful paragliders. ', 'spans': [(1228, 1257)]},\n",
       "  {'text': 'She thought to herself that the day was truly perfect, ',\n",
       "   'spans': [(1257, 1312)]},\n",
       "  {'text': 'and all anxieties from her daily life were absent for a while. ',\n",
       "   'spans': [(1312, 1375)]},\n",
       "  {'text': 'She closed her eyes for a few seconds to savor the moment ',\n",
       "   'spans': [(1375, 1433)]},\n",
       "  {'text': 'before going to lie down next to Kaylie ',\n",
       "   'spans': [(1433, 1473)]},\n",
       "  {'text': 'in the warm sand.', 'spans': [(1473, 1490)]}],\n",
       " 'response_transcript': 'It was a hot, sunny day and Rachel and her friend Kaylie decided it would be a good day to go to the beach.  They headed out to Old Orchard beach in Maine.  The sun looked like a hot, yellow pellet in the sky.   There were people laying under beach umbrellas wearing wide brimmed hats. Rachael decided that she would like to lay down in the sun before going swimming.  Kaylie dedcided to go for a swim.  A little girl in a light purple bathing suit with two floaties darted out in front of her followed closely by a boy in green shorts.  Kaylie smiled to herself remembering long past beach days with her brothers.  She saw 4 teenagers flying paragliders.  She thought about this as she walked over to lay down next to Rachel, thinking about what a perfect day this was turning out to be.',\n",
       " 'response_units': [{'text': 'It was a hot, sunny day', 'spans': [(0, 23)]},\n",
       "  {'text': 'and Rachel and her friend Kaylie', 'spans': [(24, 56)]},\n",
       "  {'text': 'decided it would be a good day to go to the beach.',\n",
       "   'spans': [(57, 107)]},\n",
       "  {'text': 'They headed out to Old Orchard beach', 'spans': [(109, 145)]},\n",
       "  {'text': 'in Maine.', 'spans': [(146, 155)]},\n",
       "  {'text': 'The sun looked like a hot, yellow pellet in the sky',\n",
       "   'spans': [(157, 208)]},\n",
       "  {'text': 'There were people laying under beach umbrellas wearing wide brimmed hats.',\n",
       "   'spans': [(212, 285)]},\n",
       "  {'text': 'Rachael decided that she would like to lay down in the sun before going swimming.',\n",
       "   'spans': [(286, 367)]},\n",
       "  {'text': 'Kaylie dedcided to go for a swim.', 'spans': [(369, 402)]},\n",
       "  {'text': 'A little girl', 'spans': [(404, 417)]},\n",
       "  {'text': 'in a light purple bathing suit', 'spans': [(418, 448)]},\n",
       "  {'text': 'with two floaties', 'spans': [(449, 466)]},\n",
       "  {'text': 'darted out in front of her', 'spans': [(467, 493)]},\n",
       "  {'text': 'followed closely by a boy', 'spans': [(494, 519)]},\n",
       "  {'text': 'in green shorts', 'spans': [(520, 535)]},\n",
       "  {'text': '.  Kaylie smiled to herself remembering long past beach days',\n",
       "   'spans': [(535, 595)]},\n",
       "  {'text': 'with her brothers', 'spans': [(596, 613)]},\n",
       "  {'text': '.  She saw 4 teenagers', 'spans': [(613, 635)]},\n",
       "  {'text': 'flying paragliders', 'spans': [(636, 654)]},\n",
       "  {'text': '.  She thought about this as she walked over to lay down next to Rachel,',\n",
       "   'spans': [(654, 726)]},\n",
       "  {'text': 'thinking about what a perfect day this was turning out to be',\n",
       "   'spans': [(727, 787)]}],\n",
       " 'matches': array([[ True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False,  True, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = 'C:/Users/gunnj/compmempy/data/narrative'\n",
    "dataset = SBS_NarrativeDataset(data_directory)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
