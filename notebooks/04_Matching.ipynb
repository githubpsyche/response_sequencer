{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp matching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcher\n",
    "The Matcher abstract class defines the interface for implementations that match response units with target items. Example concrete implementations of this class can utilize methods such as keyword matching, similarity measures, or machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Union, Dict\n",
    "import numpy as np\n",
    "\n",
    "class Matcher(ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Abstract base class for implementing response unit matching \n",
    "    strategies. To create a custom matcher, inherit from this \n",
    "    class and override the match method.\n",
    "    \"\"\" \n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, \n",
    "               response_units: Union[List[str], List[Dict[str, object]]], \n",
    "               target_items: Union[List[str], List[Dict[str, object]]],\n",
    "               response_context: str, target_context: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Matches the response_units to target_items based on a specific strategy.\n",
    "\n",
    "        Args:\n",
    "            response_units (Union[List[str], List[Dict[str, object]]]): List of response units. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            target_items (Union[List[str], List[Dict[str, object]]]): List of target items. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            response_context (str): The context of the response units.\n",
    "            target_context (str): The context of the target items.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: A boolean matrix of shape (len(target_items), len(response_units)). \n",
    "                Each element in the matrix indicates whether the corresponding\n",
    "                response unit matches the corresponding target item.\n",
    "        \"\"\"\n",
    "\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Score Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from response_sequencer.scoring import Scorer\n",
    "from typing import Optional\n",
    "from response_sequencer.filtering import MatchFilter\n",
    "\n",
    "class MaximumScoreMatcher(Matcher):\n",
    "    \"\"\"\n",
    "    Concrete Matcher class that implements a maximum score approach\n",
    "    for matching response units with target items. Utilizes a provided Scorer\n",
    "    to compute scores and a Thresholder for filtering out low-quality matches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scorer: Scorer, match_filter: Optional[MatchFilter] = None):\n",
    "        \"\"\"\n",
    "        Initializes the MaximumScoreMatcher with a specified scorer and thresholder.\n",
    "\n",
    "        Args:\n",
    "            scorer (Scorer): An initialized Scorer object.\n",
    "            match_filter Optional[MatchFilter]: Optional initialized MatchFilter object.\n",
    "        \"\"\"\n",
    "        self.scorer = scorer\n",
    "        self.match_filter = match_filter\n",
    "\n",
    "    def __call__(self, \n",
    "               response_units: Union[List[str], List[Dict[str, object]]], \n",
    "               target_items: Union[List[str], List[Dict[str, object]]],\n",
    "               response_context: str = '', target_context: str = '') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Matches the response_units to target_items based on a specific strategy.\n",
    "\n",
    "        Args:\n",
    "            response_units (Union[List[str], List[Dict[str, object]]]): List of response units. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            target_items (Union[List[str], List[Dict[str, object]]]): List of target items. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            response_context (str): The context of the response units.\n",
    "            target_context (str): The context of the target items.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: A boolean matrix of shape (len(target_items), len(response_units)). \n",
    "                Each element in the matrix indicates whether the corresponding\n",
    "                response unit matches the corresponding target item.\n",
    "        \"\"\"\n",
    "\n",
    "        scores_matrix = self.scorer(response_units, target_items, response_context, target_context)\n",
    "        if self.match_filter is not None:\n",
    "            scores_matrix = self.match_filter(response_units, target_items, scores_matrix)\n",
    "\n",
    "        max_indices = np.argmax(scores_matrix, axis=1)\n",
    "        max_values = scores_matrix[np.arange(len(target_items)), max_indices]\n",
    "\n",
    "        match_matrix = np.zeros((len(target_items), len(response_units)), dtype=bool)\n",
    "        match_matrix[np.arange(len(target_items)), max_indices] = (max_values != -np.inf)\n",
    "        return match_matrix\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Single Assignment Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from response_sequencer.scoring import Scorer\n",
    "from response_sequencer.filtering import MatchFilter\n",
    "\n",
    "class OptimalSingleAssignmentMatcher(Matcher):\n",
    "    \"\"\"\n",
    "    Concrete Matcher class that implements an optimal assignment approach\n",
    "    for matching response units with target items. Utilizes a provided Scorer\n",
    "    to compute similarity scores and a Thresholder for filtering out low-quality matches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scorer: Scorer, match_filter: Optional[MatchFilter] = None):\n",
    "        \"\"\"\n",
    "        Initializes the MaximumScoreMatcher with a specified scorer and thresholder.\n",
    "\n",
    "        Args:\n",
    "            scorer (Scorer): An initialized Scorer object.\n",
    "            match_filter Optional[MatchFilter]: Optional initialized MatchFilter object.\n",
    "        \"\"\"\n",
    "        self.scorer = scorer\n",
    "        self.match_filter = match_filter\n",
    "\n",
    "    def __call__(self, \n",
    "               response_units: Union[List[str], List[Dict[str, object]]], \n",
    "               target_items: Union[List[str], List[Dict[str, object]]],\n",
    "               response_context: str = '', target_context: str = '') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Matches the response_units to target_items based on a specific strategy.\n",
    "\n",
    "        Args:\n",
    "            response_units (Union[List[str], List[Dict[str, object]]]): List of response units. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            target_items (Union[List[str], List[Dict[str, object]]]): List of target items. \n",
    "                Each response unit can be a string or a dictionary (when both text and spans are available).\n",
    "\n",
    "            response_context (str): The context of the response units.\n",
    "            target_context (str): The context of the target items.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: A boolean matrix of shape (len(target_items), len(response_units)). \n",
    "                Each element in the matrix indicates whether the corresponding\n",
    "                response unit matches the corresponding target item.\n",
    "        \"\"\"\n",
    "\n",
    "        scores_matrix = self.scorer(response_units, target_items, response_context, target_context)\n",
    "        if self.match_filter is not None:\n",
    "            scores_matrix = self.match_filter(response_units, target_items, scores_matrix)\n",
    "\n",
    "        target_indices, response_indices = linear_sum_assignment(-scores_matrix)\n",
    "\n",
    "        match_matrix = np.zeros((len(target_items), len(response_units)), dtype=bool)\n",
    "        valid_indices = scores_matrix[target_indices, response_indices] != -np.inf\n",
    "        match_matrix[target_indices[valid_indices], response_indices[valid_indices]] = True\n",
    "\n",
    "        return match_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entailment Matcher (Currently Out of Date as of 3/31)\n",
    "Given two sentences, are these contradicting each other, entailing one the other or are these netural? Cross encoder models provided by `sentence_transformers` were trained on the SNLI and MultiNLI datasets. They produce a value 0...1 for each of the `['contradiction', 'entailment', 'neutral']` classes. First input is premise, second input is hypothesis (the sentence that is checked if it is entailed by the premise).\n",
    "\n",
    "Here we demo matching by an entailment or NLI cross encoder. Response units are matched to a target unit if the target unit is found to be entailed by the response unit. This helps identify responses that might differ in meaning from the target unit, but nonetheless contain its meaning. However, since coherent text naturally includes sentences that are entailed by other sentences, this approach could lead to spurious matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "class MaximumEntailmentMatcher(Matcher):\n",
    "    def __init__(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Initialize the MaximumEntailmentMatcher with a specified model.\n",
    "\n",
    "        :param model_name: The name of the CrossEncoder model to use.\n",
    "        \"\"\"\n",
    "        self.model = CrossEncoder(model_name)\n",
    "\n",
    "    def match(self, response_units: list, target_items: list) -> list:\n",
    "        \"\"\"\n",
    "        Match response units with target items using the CrossEncoder model\n",
    "        based on maximum entailment scores.\n",
    "\n",
    "        Args:\n",
    "            response_units (List[str]): List of response items.\n",
    "            target_items (List[str]): List of target items.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: For each response unit, a string containing the matched target item. Empty strings are used for unmatched responses\n",
    "        \"\"\"\n",
    "        pair_scores = self.model.predict(list(product(response_units, target_items)))\n",
    "        entailment_scores = []\n",
    "        for pair_score in pair_scores:\n",
    "            if np.argmax(pair_score) == 1:\n",
    "                entailment_scores.append(pair_score[1])\n",
    "            else:\n",
    "                entailment_scores.append(0.0)\n",
    "                \n",
    "        scores_matrix = [entailment_scores[i:i + len(target_items)] for i in range(0, len(entailment_scores), len(target_items))]\n",
    "\n",
    "        matched_items = [\"\" for _ in range(len(response_units))]\n",
    "        for response_index, row in enumerate(scores_matrix):\n",
    "            max_score_index = row.index(max(row))\n",
    "            if max(row) > 0:\n",
    "                matched_items[response_index] = target_items[max_score_index]\n",
    "\n",
    "        return matched_items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Entailment Matcher\n",
    "A stronger test of equivalence between two sentences is mutual entailment. This is a two-way test, and if both directions are entailed, we can be more confident that the two sentences are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MutualEntailmentMatcher(Matcher):\n",
    "    def __init__(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Initialize the MutualEntailmentMatcher with a specified model.\n",
    "\n",
    "        :param model_name: The name of the CrossEncoder model to use.\n",
    "        \"\"\"\n",
    "        self.model = CrossEncoder(model_name)\n",
    "\n",
    "    def match(self, response_units: list, target_items: list) -> list:\n",
    "        \"\"\"\n",
    "        Match response units with target items using the CrossEncoder model\n",
    "        based on mutual entailment.\n",
    "\n",
    "        Args:\n",
    "            response_units (List[str]): List of response items.\n",
    "            target_items (List[str]): List of target items.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: For each response unit, a string containing the matched target item. Empty strings are used for unmatched responses\n",
    "        \"\"\"\n",
    "        forward_pair_scores = self.model.predict(list(product(response_units, target_items)))\n",
    "        backward_pair_scores = self.model.predict(list(product(target_items, response_units)))\n",
    "\n",
    "        forward_entailment_scores = []\n",
    "        for pair_score in forward_pair_scores:\n",
    "            if np.argmax(pair_score) == 1:\n",
    "                forward_entailment_scores.append(pair_score[1])\n",
    "            else:\n",
    "                forward_entailment_scores.append(0.0)\n",
    "        \n",
    "        backward_entailment_scores = []\n",
    "        for pair_score in backward_pair_scores:\n",
    "            if np.argmax(pair_score) == 1:\n",
    "                backward_entailment_scores.append(pair_score[1])\n",
    "            else:\n",
    "                backward_entailment_scores.append(0.0)\n",
    "\n",
    "        minimum_entailment_scores = [min(forward_entailment_scores[i], backward_entailment_scores[i])\n",
    "                                        for i in range(len(forward_entailment_scores))]\n",
    "\n",
    "        forward_scores_matrix = [forward_entailment_scores[i:i + len(target_items)] for i in range(0, len(forward_entailment_scores), len(target_items))]\n",
    "        minimum_scores_matrix = [minimum_entailment_scores[i:i + len(target_items)] for i in range(0, len(minimum_entailment_scores), len(target_items))]\n",
    "\n",
    "        matched_items = [\"\" for _ in range(len(response_units))]\n",
    "        for row_index, row in enumerate(forward_scores_matrix):\n",
    "            max_score_index = row.index(max(row))\n",
    "            if minimum_scores_matrix[row_index][max_score_index] > 0:\n",
    "                matched_items[row_index] = target_items[max_score_index]\n",
    "\n",
    "        return matched_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
