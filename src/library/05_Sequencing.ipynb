{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sequencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencer\n",
    "The Sequencer abstract class defines the interface for implementations that identify the sequence of target items generated in raw response text. Example concrete implementations of this class can be based on compositions of Segmenter and Matcher strategies or on more holistic heuristic or statistical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: specify the abstract class for implementing target item sequencing strategies\n",
    "\n",
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "class Sequencer(ABC):\n",
    "\n",
    "    \"\"\"\n",
    "    Abstract base class for implementing target item sequencing strategies. To create a custom sequencer, inherit from this class and override the sequence method.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = '') -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "        Identifies the sequence of target items in the input text using the\n",
    "        provided Segmenter and Matcher instances.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to be segmented.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: Dictionary containing:\n",
    "                - 'target_context': The string containing the context of the target items. (if applicable)\n",
    "                - 'target_items': The list of target items\n",
    "                - 'response_transcript': The input text\n",
    "                - 'response_units': The list of response units, a dictionary of the form {'text': str, 'span' [(start, end)]}\n",
    "                - 'matches': a 2-D boolean numpy array of shape (len(target_items), len(response_units)) containing True if the target item matches the response unit at the corresponding index.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Sequencer\n",
    "A concrete class that allows users to compose concrete Segmenter and Matcher classes to identify the sequence of target items generated in a trial. This class should provide a flexible way to create and test various Segmenter and Matcher implementations combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: implement a pipeline sequencer that composes a segmenter and matcher to identify the sequence of target items generated in a response text\n",
    "\n",
    "#| export\n",
    "from response_sequencer.segmenting import Segmenter\n",
    "from response_sequencer.matching import Matcher\n",
    "import numpy as np\n",
    "\n",
    "class PipelineSequencer(Sequencer):\n",
    "    \"\"\"\n",
    "    Concrete implementation of Sequencer that composes Segmenter and Matcher\n",
    "    classes to identify the sequence of target items generated in a response text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segmenter: Segmenter, matcher: Matcher):\n",
    "        \"\"\"\n",
    "        Initializes the PipelineSequencer with a given Segmenter and Matcher.\n",
    "\n",
    "        Parameters:\n",
    "            segmenter (Segmenter): An instance of a concrete Segmenter implementation.\n",
    "        matcher (Matcher): An instance of a concrete Matcher implementation.\n",
    "        \"\"\"\n",
    "        self.segmenter = segmenter\n",
    "        self.matcher = matcher\n",
    "\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = '') -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "        Identifies the sequence of target items in the input text using the\n",
    "        provided Segmenter and Matcher instances.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to be segmented.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: Dictionary containing:\n",
    "                - 'target_context': The string containing the context of the target items. (if applicable)\n",
    "                - 'target_items': The list of target items\n",
    "                - 'response_transcript': The input text\n",
    "                - 'response_units': The list of response units, a dictionary of the form {'text': str, 'span' [(start, end)]}\n",
    "                - 'matches': list of lists representing a 2-D boolean numpy array of shape (len(target_items), len(response_units)) containing True if the target item matches the response unit at the corresponding index.\n",
    "        \"\"\"\n",
    "\n",
    "        response_units = self.segmenter(response_transcript)\n",
    "        matching = self.matcher(\n",
    "            response_units, target_items, response_transcript, target_context)\n",
    "\n",
    "        return {\n",
    "            'target_context': target_context,\n",
    "            'target_items': target_items,\n",
    "            'response_transcript': response_transcript,\n",
    "            'response_units': response_units,\n",
    "            'matches': matching\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3 Sequencer\n",
    "A concrete class that uses the GPT-3 API to generate a sequence of target items based on a given prompt. This class should provide a flexible way to create and test various GPT-3 API implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: implement a GPT-3-based sequencer that identifies the sequence of target items generated in a response text\n",
    "\n",
    "import openai\n",
    "\n",
    "class GPT3Sequencer(Sequencer):\n",
    "    \"\"\"\n",
    "    Concrete implementation of Sequencer that uses a GPT-3-based approach for\n",
    "    identifying the sequence of target items generated in a response text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"text-davinci-002\"):\n",
    "        \"\"\"\n",
    "        Initializes the GPT3Sequencer with an API key and a GPT-3 model name.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        api_key : str\n",
    "            The API key for accessing the OpenAI GPT-3 API.\n",
    "        model : str, optional\n",
    "            The GPT-3 model to be used for sequencing (default is \"text-davinci-002\").\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def sequence(self, input_text: str, target_items: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Identifies the sequence of target items in the input text using the GPT-3 model.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        input_text : str\n",
    "            The input text to be processed.\n",
    "        target_items : List[str]\n",
    "            A list of target items to identify in the input text.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        List[str]\n",
    "            A list of target items in the order they appear in the input text.\n",
    "        \"\"\"\n",
    "        prompt = f\"Given the text: '{input_text}', find the sequence of the following target items: {', '.join(target_items)}.\\n\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=50,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].text.strip()\n",
    "        sequence = result.split(\", \")\n",
    "        return sequence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Sequencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: implement a range of reference sequencers used for comparison against a baseline sequencer\n",
    "\n",
    "#| export\n",
    "from response_sequencer.segmenting import MultiSentenceFragmentsSegmenter, SentenceSegmenter\n",
    "from response_sequencer.scoring import ContextualizedEmbeddingScorer, SentenceTransformerScorer\n",
    "from response_sequencer.matching import MaximumScoreMatcher\n",
    "\n",
    "class BaselineSequencer(Sequencer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        model_name = 'all-mpnet-base-v2'\n",
    "        segmenter = SentenceSegmenter()\n",
    "        scorer = SentenceTransformerScorer(\n",
    "            model_name='all-mpnet-base-v2')\n",
    "        matcher = MaximumScoreMatcher(scorer)\n",
    "        self.sequencer = PipelineSequencer(segmenter, matcher)\n",
    "\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = ''\n",
    "        ) -> Dict[str, object]:\n",
    "\n",
    "            return self.sequencer(response_transcript, target_items, target_context)\n",
    "\n",
    "class BaselinePlusContextSequencer(Sequencer):\n",
    "    def __init__(self):\n",
    "        layer_depth = 1\n",
    "        model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "        segmenter = SentenceSegmenter()\n",
    "        scorer = ContextualizedEmbeddingScorer(\n",
    "            model_name=model_name,\n",
    "            layer_depth=layer_depth)\n",
    "        matcher = MaximumScoreMatcher(scorer)\n",
    "        self.sequencer = PipelineSequencer(segmenter, matcher)\n",
    "\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = ''\n",
    "        ) -> Dict[str, object]:\n",
    "\n",
    "            return self.sequencer(response_transcript, target_items, target_context)\n",
    "\n",
    "class BaselinePlusFragmentsSequencer(Sequencer):\n",
    "\n",
    "    def __init__(self):\n",
    "        min_tokens = 2\n",
    "        max_sentences = 2\n",
    "        model_name = 'all-mpnet-base-v2'\n",
    "        segmenter = MultiSentenceFragmentsSegmenter(\n",
    "            max_sentences=max_sentences, min_tokens=min_tokens)\n",
    "        scorer = SentenceTransformerScorer(\n",
    "            model_name=model_name)\n",
    "        matcher = MaximumScoreMatcher(scorer)\n",
    "        self.sequencer = PipelineSequencer(segmenter, matcher)\n",
    "\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = ''\n",
    "        ) -> Dict[str, object]:\n",
    "\n",
    "            return self.sequencer(response_transcript, target_items, target_context)\n",
    "\n",
    "class BaselinePlusContextPlusFragmentsSequencer(Sequencer):\n",
    "\n",
    "    def __init__(self):\n",
    "        layer_depth = 1\n",
    "        min_tokens = 2\n",
    "        max_sentences = 2\n",
    "        model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "        segmenter = MultiSentenceFragmentsSegmenter(\n",
    "            max_sentences=max_sentences, min_tokens=min_tokens)\n",
    "        scorer = ContextualizedEmbeddingScorer(\n",
    "            model_name=model_name,\n",
    "            layer_depth=layer_depth)\n",
    "        matcher = MaximumScoreMatcher(scorer)\n",
    "        self.sequencer = PipelineSequencer(segmenter, matcher)\n",
    "\n",
    "    def __call__(\n",
    "        self, response_transcript: str, target_items: List[str], target_context: str = ''\n",
    "        ) -> Dict[str, object]:\n",
    "\n",
    "            return self.sequencer(response_transcript, target_items, target_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target_context': '',\n",
       "  'target_items': ['(n) ace (one of four playing cards in a deck having a single pip on its face)',\n",
       "   '(n) ace, adept, champion, sensation, maven, mavin, virtuoso, genius, hotshot, star, superstar, whiz, whizz, wizard, wiz (someone who is dazzlingly skilled in any field)',\n",
       "   '(n) ace (a serve that the receiver is unable to reach)'],\n",
       "  'response_transcript': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um, an ace can be someone that's really good at something.\",\n",
       "  'response_units': [{'text': \"Ace, um, I think it's like a, something to do with tennis, I don't really know.\",\n",
       "    'spans': [[0, 79]]},\n",
       "   {'text': \"Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long.\",\n",
       "    'spans': [[80, 237]]},\n",
       "   {'text': \"Um, an ace can be someone that's really good at something.\",\n",
       "    'spans': [[238, 296]]}],\n",
       "  'matches': [[False, True, False],\n",
       "   [False, False, True],\n",
       "   [True, False, False]]},\n",
       " {'target_context': '',\n",
       "  'target_items': ['(n) ace (one of four playing cards in a deck having a single pip on its face)',\n",
       "   '(n) ace, adept, champion, sensation, maven, mavin, virtuoso, genius, hotshot, star, superstar, whiz, whizz, wizard, wiz (someone who is dazzlingly skilled in any field)',\n",
       "   '(n) ace (a serve that the receiver is unable to reach)'],\n",
       "  'response_transcript': \"Ace, um, I think it's like a, something to do with tennis, I don't really know. Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long. Um, an ace can be someone that's really good at something.\",\n",
       "  'response_units': [{'text': \"Ace, um, I think it's like a, something to do with tennis, I don't really know.\",\n",
       "    'spans': [[0, 79]]},\n",
       "   {'text': \"Um, there's also, like, um, in a card game there's the ace, um, which is like generally, like the highest point card, God, I haven't played cards in so long.\",\n",
       "    'spans': [[80, 237]]},\n",
       "   {'text': \"Um, an ace can be someone that's really good at something.\",\n",
       "    'spans': [[238, 296]]}],\n",
       "  'matches': [[False, True, False],\n",
       "   [False, False, True],\n",
       "   [True, False, False]]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-summary: demonstrate the use of the baseline sequencer\n",
    "\n",
    "from response_sequencer.datasets import SensesDataset\n",
    "from response_sequencer.demo import flatten_matches\n",
    "import os\n",
    "import json\n",
    "\n",
    "section_tag = 'base' # unique identifier for this variation of notebook parameters\n",
    "output_dir = '../../data/'\n",
    "\n",
    "dataset = SensesDataset(\n",
    "    os.path.join(output_dir, f'{section_tag}_senses.h5'), \n",
    "    os.path.join(output_dir, f'{section_tag}_sense_pool.txt'))\n",
    "sequencer = BaselineSequencer()\n",
    "\n",
    "trial_index = 0\n",
    "trial = dataset.__getitem__(trial_index)\n",
    "\n",
    "response_text = trial[\"response_transcript\"]\n",
    "matched_target_items, reference_units = flatten_matches(\n",
    "        trial['target_items'], trial['response_units'], trial['matches'])\n",
    "result = sequencer(response_text, matched_target_items)\n",
    "\n",
    "json.loads(json.dumps([result, result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
