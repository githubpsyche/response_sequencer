{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: demonstrate how the DatasetEvaluator can be used to evaluate the performance of the Sequencer\n",
    "\n",
    "from response_sequencer.segmenting import MultiSentenceFragmentsSegmenter\n",
    "from response_sequencer.matching import MaximumScoreMatcher\n",
    "from response_sequencer.scoring import ContextualizedEmbeddingScorer\n",
    "from response_sequencer.sequencing import PipelineSequencer\n",
    "from response_sequencer.datasets import SBS_NarrativeDataset\n",
    "\n",
    "datasets = [SBS_NarrativeDataset('C:/Users/gunnj/compmempy/data/narrative'), dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for min_tokens in [1]:\n",
    "        for layer_depth in [3]:\n",
    "\n",
    "            segmenter = MultiSentenceFragmentsSegmenter(max_sentences=1, min_tokens=min_tokens)\n",
    "            scorer = ContextualizedEmbeddingScorer(\n",
    "                model_name='sentence-transformers/all-mpnet-base-v2', layer_depth=layer_depth)\n",
    "            matcher = MaximumScoreMatcher(scorer)\n",
    "            sequencer = PipelineSequencer(segmenter, matcher)\n",
    "\n",
    "            generated_dataset = DatasetGenerator()(dataset, sequencer, samples=5, random=True)\n",
    "\n",
    "            dataset_evaluator = DatasetEvaluator(dataset,  generated_dataset)\n",
    "\n",
    "            scores = dataset_evaluator(LevenshteinMatcherEvaluator(only_matched=True))\n",
    "\n",
    "    print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
